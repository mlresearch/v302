@Proceedings{DLI-2025,
    booktitle = {DLI 2025 Research Track},
    name = {Deep Learning Indaba},
    shortname = {DLI},
    editor = {Proceedings of Machine Learning Research},
    volume = {302},
    year = {2025},
    start = {2025-07-17},
    end = {2025-07-22},
    published = {2026-02-13},
    conference_url = {https://deeplearningindaba.com/2025/},
    address = {University of Rwanda, Kigali, Rwanda}
}

@InProceedings{benhajhmida25,
    title = {A Fully Neural Tunisian Arabic TTS System},
    author = {Ben HajHmida, Moez and Haddad, Hatem and Ben El Haj Mabrouk, Aymen },
    pages = {1-10},
    abstract = {The discipline of Text-To-Speech (TTS) focuses on the artificial generation of spoken language from text, a technology increasingly vital for voice-based applications. Recognizing the rising demand for realistic computer-generated speech, especially for under-represented accents and dialects, this research is driven by the goal of constructing a high-quality Tunisian Arabic TTS system. Highlighting the underdeveloped state of advanced natural language processing technologies like TTS in Tunisia, this paper introduces our work on recording a dedicated Tunisian female Arabic speech dataset. Furthermore, we present an end-to-end deep learning TTS system built upon a deep neural network architecture. A subjective evaluation using Mean Opinion Score (MOS) was conducted, comparing our approach to end-to-end generative and concatenative models. The results of this evaluation indicate that our proposed system outperforms both baselines in terms of both naturalness and intelligibility.
    <b>Keywords</b>: Text-To-Speech, Dialects, Deep Neural Networks, Tacotron 2, WaveRNN, Griffin-Lim Algorithm.}
}

@InProceedings{nigusie25,
    title = {Sentiment Polarity Analysis of Amharic Climate Change Discourse Using Large Language Models},
    author = {Nigusie, Gebregziabihier and Mossa, Neima and Tegegne, Tesfa },
    pages = {1-10},
    abstract = {Climate change refers to variations in temperature and weather conditions due to various climate-related factors on earth. These factors vary across regions, and people’s perceptions of climate change. Analyzing public opinion on climate change at a regional level is crucial for developing targeted solutions. However, manually analyzing large volumes of data is challenging for informed dissension. Applying emerging pre-trained Large Language Models offers a promising solution for eﬀiciently analyzing large datasets and understanding public perspectives on climate change. Amharic is one of the widely spoken African languages. Many speakers of the language are actively discussing and expressing their opinions on various topics, including climate change, on social media. Given the increasing discussions about climate change, this study focuses on the sentiment analysis of Amharic climate texts. We collected 6013 sentences from social media and news sources. The data is annotated manually by native speakers to its target polarity. We conducted experiments using the LLM that supports African languages during pre-training. In this study, MultilingualBert and AfriBERTa models were employed with hyperparameter tuning to perform sentiment polarity analysis on Amharic climate text. The experimental results shows that MultilingualBert outperforms AfriBERTa, achieving an accuracy of 69%. This performance is attributed to MultilingualBert’s enhanced capability to capture token-level semantics by giving a variety of attention across tokens, thereby improving its contextual understanding in downstream sentiment classification tasks.
    <b>Keywords</b>: Climate NLP, Sentiment, LLM, mBERT, AfriBERTa, Climate Sentiment.}
}

@InProceedings{rassou25,
    title = {Combatting Language Forgetting in Low-Resourced Settings},
    author = {Rassou, Emmanuel},
    pages = {1-11},
    abstract = {Neural machine translation becomes a continual learning challenge as language evolves over time. While Transformer-based models excel at capturing linguistic patterns from large corpora, they require continual updates to adapt to new language use without losing previously acquired knowledge. In this work, we introduce Latent Replay Buffers to the NLP domain for the first time by implementing and fine-tuning our Latent Replay Transformer. We conduct initial experiments for low-resource languages on Small-100, a distilled version of a multilingual transformer trained on 100 languages, to be well-suited for deployment in memory- and data-constrained environments. Our findings reveal an intriguing trade-off in the selection of latent activations to store for effective replay. We release our code to support both the Continual Learning and NLP for Low-Resourced Languages communities.
    <b>Keywords</b>: Continual Learning, Transformers, Low-Resourced Languages.}
}

@InProceedings{rufai25,
    title = {Towards End-to-End Training of Automatic
Speech Recognition for Nigerian Pidgin},
    author = {Rufai, Amina and Abeeb, Afolabi and Oduntan, Esther and Arulogun, Tayo and Adegboro, Oluwabukola and Ajisafe, Daniel},
    pages = {1-10},
    abstract = {The prevalence of automatic speech recognition (ASR) systems in spoken language applications has increased significantly in recent years. Notably, many African languages lack sufficient linguistic resources to support the robustness of these systems. This paper focuses on the development of an end-to-end speech recognition system customised for Nigerian Pidgin English. We investigated and evaluated different pretrained state-of-the-art architectures on a new dataset. Our empirical results demonstrate a notable performance of the variant Wav2Vec2 XLSR-53 on our dataset, achieving a word error rate (WER) of 29.6% on the test set, surpassing other architectures such as NeMo QuartzNet and Wav2Vec2.0 Base-100H in quantitative assessments. Additionally, we demonstrate that a pretrained state-of-the-art model does not work well out-of-the-box. We performed zero-shot evaluation using XLSR-English as the baseline, chosen for its similarity to Nigerian Pidgin. This yielded a higher WER of 73.7%. By adapting this architecture to nuances represented in our dataset, we reduce error by 59.84%. Our dataset comprises 4,277 recorded utterances from native speakers, partitioned into training, validation, and test sets. This study underscores the potential for improving ASR systems for under-resourced languages like Nigerian Pidgin English, contributing to greater inclusion in speech technology applications. We publicly release our unique parallel dataset (speech-to-text) on Nigerian Pidgin, as well as the model weights on Hugging Face. Our project and code are made available to foster future research from the community.
    <b>Keywords</b>: Automatic Speech Recognition, ASR, Nigerian Pidgin English, End-to-End.}
}

@InProceedings{aliyu25,
    title = {Evaluating Deep Learning Models for African Wildlife Image
Classification: From DenseNet to Vision Transformers},
    author = {Aliyu, Lukman and Muhammad, Umar and Ismail, Bikisu and Wakili, Almustapha and Yimam, Seid and Muhammad, Shamsuddeen and Abdullahi, Mustapha},
    pages = {1-14},
    abstract = {Wildlife populations in Africa face severe threats, with vertebrate numbers declining by over 65% in the past five decades. In response, image classification using deep learning has emerged as a promising tool for biodiversity monitoring and conservation. This paper presents a comparative study of deep learning models for automatically classifying African wildlife images, focusing on transfer learning with frozen feature extractors. Using a public dataset of four species: buffalo, elephant, rhinoceros, and zebra; we evaluate the performance of DenseNet-201, ResNet-152, EfficientNet-B4, and Vision Transformer ViT-H/14. DenseNet-201 achieved the best performance among convolutional networks (67% accuracy), while ViT-H/14 achieved the highest overall accuracy (99%), but with significantly higher computational cost, raising deployment concerns. Our experiments highlight the trade-offs between accuracy, resource requirements, and deployability. The best-performing CNN (DenseNet-201) was integrated into a Hugging Face Gradio Space for real-time field use, demonstrating the feasibility of deploying lightweight models in conservation settings. This work contributes to African-grounded AI research by offering practical insights into model selection, dataset preparation, and responsible deployment of deep learning tools for wildlife conservation.
    <b>Keywords</b>:Image Classification, DenseNet, African wildlife, Computer Vision, Deep learning.}
}

@InProceedings{bolarinwa25,
    title = {Closing the Gap in Low-Resource ASR: Leveraging Multilingual Models for Code-Switched Yoruba-English Speech},
    author = {Bolarinwa, Emmanuel and Babatunde, Oreoluwa and Olufemi, Victor and Moshood, Kausar and Williams, Oluwademilade},
    pages = {1-9},
    abstract = {Recent advancements in Automatic Speech Recognition (ASR) have revolutionized voice-based technologies, yet challenges persist in achieving accurate recognition for multilingual and low-resource languages. This research explores the performance of state-of-the-art multilingual ASR models (Whisper Large v3 and MMS-1B-All) on Yoruba-English code-switched (CS) speech. Despite notable progress in multilingual ASR, code-switching remains a complex challenge due to the linguistic intricacies introduced by phonetic, syntactic, and lexical shifts within single utterances. This study addresses a significant gap in the literature by evaluating these models on a 21-hour Yoruba-English dataset and finetuned for domain-specific performance. Results show that fine-tuning led to substantial improvements in Word Error Rate (WER), with MMS-1B-All achieving a 55.8\% reduction and Whisper Large v3 showing a 50.1\% reduction. Although MMS-1B-All outperformed Whisper Large v3 slightly, both models demonstrated strong potential for ASR in Yoruba-English CS speech recognition. This study highlights the feasibility of fine-tuning multilingual ASR models for low-resource code-switched scenarios and suggests directions for future research, including dataset expansion, alternative fine-tuning strategies, and real-time performance evaluation. <b>Keywords</b>: automatic speech recognition, code-switching, multilingual ASR, low-resource languages}
}

@InProceedings{haddad25,
    title = {Zero-Shot LLM Generation of Energy Notifications for
African Languages: A Benchmark Study},
    author = {Haddad, Hatem and Jerbi, Feres and Smaali, Issam},
    pages = {1-10},
    abstract = {Large Language Models (LLMs) have demonstrated significant advancements in natural language applications but often exhibit performance disparities for low-resource languages, particularly African languages underrepresented in training corpora. This paper addresses this gap by evaluating the zero-shot text generation capabilities of LLMs within the energy domain for six widely spoken African languages. We introduce a novel multilingual benchmark dataset of energy management notifications and use it to assess four recent open-source LLMs (1B-7B parameters). Employing a zero-shot learning approach with multiple prompts and established NLP metrics (Statistics-based, Model-based, Perplexity) without fine-tuning, our findings reveal varying model strengths across languages and metrics. For instance, while some models excel in content overlap (ROUGE) for languages like English and French, others show better fluency (Perplexity) or semantic similarity (BERTScore), with performance shifting notably for African languages.}
}

@InProceedings{zulu25,
    title = {An AI Tomato Leaf Doctor Using MobileNetV2 and
Streamlit: A Lightweight Deep Learning Tool for Farmers},
    author = {Zulu, Makepeace},
    pages = {1-12},
    abstract = {Tomato farming in Eswatini faces severe yield losses (up to 70 percent) due to diseases such as late blight (Phytophthora infestans) and bacterial leaf spot (Xanthomonas spp.), caused by climate variability and limited access to localized diagnostic tools. Existing AI solutions, such as Plantix, lack region-specific treatment advice, excluding farmers in low bandwidth areas. This study introduces AI Tomato Leaf Doctor, a Streamlit deployed, two stage MobileNetV2 system pretrained on ImageNet and fine-tuned. From experimental analysis, it is seen that plant leaf disease detection using MobileNetV2 outperforms existing approach in terms of accuracy as well as training time. The first model filters non tomato inputs, other plants or objects, while the second classifies ten tomato conditions (nine diseases and one healthy) using a PlantVillage dataset of 20,000 images (2000 per class). The model achieved 97 percent accuracy. The app provides chemical dosages for locally available fungicides and their market prices in Eswatini Lilangeni (SZL), delivered via a farmer friendly interface. By leveraging MobileNetV2’s lightweight design and Streamlit’s cloud compatibility, this work bridges the gap between AI innovation and the practical needs of Eswatini’s tomato-dependent households.
    <b>Keywords</b>: Tomato Disease Detection, MobileNetV2, Streamlit, PlantVillage Dataset, Eswatini Agriculture, Lightweight CNN.}
}

@InProceedings{anku25,
    title = {Adult weight estimation in a tertiary hospital in Ghana},
    author = {Anku, Eric and Sam, Margaret and Mohammed, Seidu and Asa-Atiemo, Abena and Ekor, Oluwayemisi},
    pages = {1-11},
    abstract = {Accurate weight estimation is essential for estimating nutritional requirements for patients, especially among bedridden patients, where direct measurement is often not feasible due to the absence of bed scales. In such scenarios, clinicians rely on existing predictive equations, visual assessments, or patient-reported estimates. However, many existing predictive equations were developed in distinct demographic groups and may lack applicability without localised validation. This study employed a cross-sectional design involving 389 adult patients at the Cape Coast Teaching Hospital to develop and evaluate weight estimation models. Standardised protocols were followed to collect anthropometric measurements, including weight, height, mid-upper arm circumference (MUAC), and calf circumference (CC). Each variable was measured twice, and the mean of the two measurements was used for subsequent analysis. The dataset was partitioned into a training set (80\%) and a testing set (20\%). Automated machine learning algorithms were trained utilising the H2O.ai framework. Model performance was assessed using the mean absolute error (MAE), root mean squared error (RMSE), coefficient of determination (R2), and the proportion of predictions falling within 10\% (P10) and 20\% (P20) of the actual weight. Pre-existing, relevant equations were applied to predict weight on the complete dataset, and the resulting predictions were evaluated against the actual weight using MAE, RMSE, R2, P10, and P20. The average age of participants in the study was 57 years (interquartile range [IQR]: 42-66). The majority of the participants were females (66\%). The average weight was 65 kg (IQR: 58-72), with the majority (46\%) of participants having a normal body mass index (BMI) status. Our AutoML-derived stacked ensemble model outperformed all evaluated methods, achieving lower error rates (MAE of 3 kg and RMSE of 4 kg), a high R2 of 0.9 and P10 and P20 values of 90\% and 100\%, respectively. While this current study highlights the importance of locally trained models, generalisability remains a limitation and warrants further validation across broader populations. Regardless, this study contributes important evidence for the development of population-specific adult weight estimation models to support clinical decision making.}
}

@InProceedings{nyalala25,
    title = {Culturally Attuned and Resource-Aware Foundation Models
for East African Agriculture: A Theoretical Framework and Research Agenda},
    author = {Nyalala, Innocent and Bhatt, Nirav},
    pages = {1-11},
    abstract = {East African agriculture supports more than 175 million people but faces mounting challenges from climate change, resource constraints, and information access barriers. Current foundation models fail to address the region’s computational limitations (devices with 1-4GB RAM), linguistic diversity (200+ languages), and knowledge system differences. This paper presents CARA-FM (Culturally Attuned and Resource-Aware Foundation Models), a theoretical framework comprising four pillars: Community-Driven Data Architecture, Indigenous Knowledge Systems, Edge-First Model Design, and Participatory Governance. We propose evaluation metrics that span the technical (computational efficiency), agricultural (yield improvement), and cultural (community acceptance) dimensions. Although empirically unvalidated, this framework provides a research agenda for developing agricultural AI systems that operate within severe resource constraints and respect local contexts. Our contribution is theoretical and offers a blueprint for future empirical work rather than implemented solutions.
    <b>Keywords</b>: Foundation Models, Agricultural AI, Theoretical Framework, East Africa, Resource-Constrained Computing, Indigenous Knowledge.}
}

@InProceedings{msane25,
    title = {Towards Language Representation for SiSwati: A
Comparative Analysis of Sub-word Tokenization Algorithms},
    author = {Thandokuhle, Msane and Hatem, Haddad},
    pages = {1-10},
    abstract = {Many African languages, including SiSwati, are underrepresented in current AI interactions due to challenges such as imprecise language representation. This study investigates various sub-word tokenization algorithms for building monolingual SiSwati tokenizers, a critical step towards enhancing its linguistic representation. We implement and compare Byte-Pair Encoding (BPE), Unigram Language Model (ULM), and WordPiece algorithms, evaluating their performance with three distinct vocabulary sizes: 32K, 50K, and 70K. The tokenizers’ outputs were assessed on a downstream sentiment analysis task using multiple classifiers. The results demonstrate that sub-word representation is effective for SiSwati and that monolingual tokenizers can achieve morphologically-aware sub-word segmentation. Notably, Unigram with a 32K vocabulary paired with an XGBoost classifier yielded the highest peak F1-score, though BPE and WordPiece also offered more stable performance across different vocabulary capacities, with 32K vocabularies often proving sufficient for these two. These findings highlight the significant interplay between tokenizer algorithm type, vocabulary size, and classifier choice in developing tools for low-resource, morphologically rich languages.
    <b>Keywords</b>: Tokenization, low-resource, vocabulary size, morphologically-rich language.}
}

@InProceedings{simon25,
    title = {Large Vocabulary Read-Mode Speech Corpora for Low-Resourced Ometo Languages: Gamo, Gofa, Dawuro and Wolaita},
    author = {Simon, Nebiyu and Melese, Micheal and Elias, Akililu},
    pages = {1-10},
    abstract = {Speech is a fundamental mode of human communication and has also become a popular way for people to interact with machines through the use of speech technology. Automatic Speech Recognition (ASR) is one of speech technologies which transcribes speech to its corresponding text using numerous techniques and facilitates communication between human and electronic devices. To make it a real large amount of speech dataset parallel with its transcription is necessary. However, developing a large amount of corpora through collection and pre-processing is very expensive for many languages, including Ometo languages. This is mainly because they are classified as low-resource languages, lacking sufficient linguistic data and technological resources. In order to solve the problem of data scarcity for Ometo languages: Gamo, Gofa, Dawuro, and Wolaita, we have developed large speech corpora of 24.3511 hr with its corresponding transcription for four Ometo languages. Then, we have developed ASR systems for each language to verify the usability of the corpora using a deep learning technique. We have achieved WER of 72.00%, 57.94%, 62.22%, 64.71% for Gamo, Gofa, Dawuro and Wolaita languages, respectively. In order to demonstrate that the corpora are appropriate for additional research toward the creation of ASR systems, we present the corpora and the baseline ASR systems we have constructed in this study. The corpora can therefore be used by researchers to improve speech processing systems. 
    <b>Keywords</b>: Automatic Speech Recognition, Low-Resource Languages, Ometo Languages, Deep Learning.}
}

@InProceedings{nahabwe25,
    title = {Benchmarking Automatic Speech Recognition Models for
African Languages},
    author = {Nahabwe, Alvin and Kagumire, Sulaiman and Musinguzi, Denis and Beijuka, Bruno and Kyagaba, Jonah and Nabende, Peter and Katumba, Andrew and Nakatumba-Nabende, Joyce},
    pages = {1-19},
    abstract = {Automatic speech recognition (ASR) for African languages remains constrained by limited labeled data and the lack of systematic guidance on model selection, data scaling, and decoding strategies. Large pre-trained systems such as Whisper, XLS-R, MMS, and W2v-BERT have expanded access to ASR technology, but their comparative behavior in African low-resource contexts has not been studied in a unified and systematic way. In this work, we benchmark four state-of-the-art ASR models across 13 African languages, fine-tuning them on progressively larger subsets of transcribed data ranging from 1 to 400 hours. Beyond reporting error rates, we provide new insights into why models behave differently under varying conditions. We show that MMS and W2v-BERT are more data efficient in very low-resource regimes, XLS-R scales more effectively as additional data becomes available, and Whisper demonstrates advantages in mid-resource conditions. We also analyze where external language model decoding yields improvements and identify cases where it plateaus or introduces additional errors, depending on the alignment between acoustic and text resources. By highlighting the interaction between pre-training coverage, model architecture, dataset domain, and resource availability, this study offers practical and insights into the design of ASR systems for underrepresented languages.
    <b>Keywords</b>: Automatic Speech Recognition, African Languages, Low-Resource ASR, Pre-trained Models, Language Modeling.}
}



@InProceedings{kanubala25,
    title = {A Fairness-Centered Comparison of Machine Learning
Models for Student Retention},
    author = {Kanubala, Deborah and Abubakari, Alidu},
    pages = {1-12},
    abstract = {Machine learning (ML) is increasingly used to support decision-making in high-stakes domains such as healthcare, finance, and criminal justice. Particularly, in education, ML applications have grown substantially, ranging from personalized learning systems to early warning systems for student success. These applications have demonstrated measurable improvements in intervention timing and resource allocation. While ML offers a wide range of benefits in education, it also risks reinforcing societal biases. In this study, we leverage different ML algorithms to predict students at risk of dropping out, hence enabling timely interventions. We further assess the fairness of these models using different group fairness notions such as demographic parity, equality of opportunity, false positive rate and accuracy parity. Our main contribution is to assess which notion of fairness is best suited for the education domain. This research aims to align the potential of ML with ethical considerations, contributing to fairer and more effective educational interventions.
    <b>Keywords</b>: Machine Learning, Student Dropout Prediction, Fairness, Education.}
}

@InProceedings{ezembey25,
    title = {\d{E}hugbo Ka! Advancing Machine Translation for the
Low-Resource \d{E}hugbo Language through Parallel Corpus
Development},
    author = {Eze-Mbey, Ukachi and Eze-Mbey, Uloma and Anjuwon, Ololade},
    pages = {1-9},
    abstract = {Despite advancements in language technologies, there consistently seems to be an exclusion of low-resource African languages and their dialects like \d{E}hugbo, a critically endangered variant of Igbo spoken by fewer than 150,000 people in Afikpo, Nigeria. This exclusion perpetuates social and linguistic inequities, leaving speakers of such dialects without access to digital tools that could preserve their language and culture. This paper presents \d{E}hugbo Ka! (”Greetings \d{E}hugbo!”) addresses this gap. We gathered and built the only publicly available parallel corpus, 1,021 \d{E}hugbo-English sentences from the New Testament of the Bible, we evaluated and fine-tuned two state-of-the-art models, M2M100 (facebook/m2m100 418M) and NLLB (facebook/nllb-200-distilled-600M). Initial results were stark: M2M100 achieved a BLEU score of 1.2188, while NLLB scored only 0.0262. After fine-tuning, M2M100 improved to 16.1719, and NLLB achieved 20.4016, demonstrating the potential of adapting LLMs for low-resource languages. Our findings reveal both promise and challenges. While fine-tuning significantly improves performance, the lack of diverse datasets limits translation quality and reinforces the need for inclusive data collection practices. This work highlights the importance of community-driven approaches, as linguistic preservation cannot be achieved without the active involvement of native speakers.This project not only advances the field of low resource MT but also serves as a call to action for researchers and developers to prioritize linguistic diversity, ensuring that no language is left behind in the digital age.
    <b>Keywords:</b> multilingual low resource, resources for less-resourced languages, minoritized languages, less resourced languages, endangered languages, indigenous languages, corpus creation, multilingual corpora, evaluation, datasets for low resource languages, Igbo, Igbo language.}
}


@InProceedings{kolawole25,
    title = {Fairness-Aware Machine Learning for Social Bias Detection
in Healthcare Research Datasets},
    author = {Kolawole, Precious},
    pages = {1-10},
    abstract = {This work presents an automated tool for detecting and measuring bias in healthcare datasets and predictive models. We evaluated fairness at both the data and algorithmic levels using metrics including Statistical Parity Difference (SPD), Equal Opportunity Difference (EOD), and Demographic Disparity. Using the SyntheticMass (healthcare expenses) and Brain Stroke healthcare datasets, we found that SyntheticMass showed substantial demographic imbalance (83.6% White patients) and age-based disparities (SPD: 0.82 for younger vs. elderly patients). While the Brain Stroke dataset exhibited more balanced demographics, we identified substantial disparities in stroke outcomes between age groups. Across both datasets, neural networks consistently outperformed traditional machine learning models on fairness metrics. In the Brain Stroke dataset, neural networks achieved both higher accuracy (94.8% vs. 91.8% for the best traditional model) and nearly perfect fairness scores (SPD: 0.000–0.0007; EOD: 0.000–0.0128). Additionally, we introduced a combined scoring metric that equally weights accuracy and fairness, providing researchers with a practical framework for model selection that prioritizes both dimensions. The interactive visualization dashboard makes fairness analysis accessible to medical researchers without specialized knowledge of fairness-aware machine learning. 
    <b>Keywords</b>: healthcare bias, fairness evaluation, machine learning, neural networks, statistical parity, equal opportunity, demographic disparity.}
}


@InProceedings{hussen25,
    title = {The State of Large Language Models for African Languages:
Progress and Challenges},
    author = {Hussen, Kedir and Sewunetie, Walelign and Ayele, Abinew and Imam, Sukairaj and Alemu, Eyob and Muhammad, Shamsuddeen and Yimam, Seid},
    pages = {1-27},
    abstract = {Large Language Models (LLMs) are transforming Natural Language Processing (NLP), but their benefits are largely absent for Africa’s 2,000 low-resource languages. This paper comparatively analyzes African language coverage across six LLMs, eight Small Language Models (SLMs), and six Specialized SLMs (SSLMs). The evaluation covers language coverage, training sets, technical limitations, script problems, and language modelling roadmaps. The work identifies 41 supported African languages and 23 available public data sets, and it shows a big gap where four languages (Amharic, Swahili, Afrikaans, and Malagasy) are always treated while there is over 98% of unsupported African languages. Moreover, the review shows that just Latin, Arabic, and Ge’ez scripts are identified while 20 active scripts are neglected. Some of the primary challenges are lack of data, tokenization biases, very high computational costs, and evaluation issues. These issues demand language standardization, corpus development by the community, and effective adaptation methods for African languages.
    <b>Keywords</b>: Large Language Models (LLMs), Small Language Models (SLMs), Low resource languages, Specialized SLMs (SSLMs)}
}

@InProceedings{muhanguzi25,
    title = {Optimisation of a Raspberry Pi-based Bioacoustic Sensor for Data Collection},
    author = {Muhanguzi, Joel and Kiarie, Gabriel and Maina, Ciira and Mwebaze, Ernest},
    pages = {1-9},
    abstract = {This paper details the optimisation of a Raspberry Pi-based bioacoustic sensing system designed for data collection for acoustic classification of birds. Optimised sensors are desirable when collecting data off-the-grid. The acoustic sensor’s power consumption was studied under various conditions, such as using a full and Lite Raspberry Pi OS to guide the sensor’s optimisation. The power management board used to power the sensor was also redesigned to improve efficiency. A machine learning model to classify 3 bird species and other sounds with an accuracy of 93% and loss of 30% on the test set was developed. An 80%-10%-10% train, test and validation split ratio was used to train and evaluate the model which was then quantized to tensorflowlite to run directly on the raspberry pi hardware in a miniaturized format. The optimised sensor was then deployed at a Wildlife Conservancy in Africa, Kenya to continously collect data and perform inference at the edge.
    <b>Keywords</b>: Bioacoustics, Raspberry Pi, Sensor Optimisation, Off-grid Data Collection, Power Management, machine learning, quantization, miniaturized.}
}

@InProceedings{habibi25,
    title = {Adaptive UAV Inspection of PV Panels Using
Goal-Conditioned Reinforcement Learning and Zigzag Coverage Planning},
    author = {Habibi, Imen and Msadaa, Ikbal and Grayaa, Khaled},
    pages = {1-17},
    abstract = {Accurate and efficient inspection of photovoltaic (PV) panels is critical for early anomaly detection and energy yield optimization. This study presents an autonomous Unmanned Aerial Vehicles UAV-based inspection framework that leverages Goal-Conditioned Reinforcement Learning (GCRL) for adaptive path tracking. The UAV follows a mathematically defined zigzag trajectory while dynamically responding to disturbances such as wind drift. Instead of rigid waypoint following, the agent is conditioned on successive inspection goals and learns optimal movement strategies using Proximal Policy Optimization (PPO). The environment incorporates realistic wind noise and UAV momentum, requiring the policy to learn corrective behaviors under uncertainty. Simulation results demonstrate the agent’s ability to achieve robust full-surface coverage, minimize overlap, and maintain trajectory alignment, highlighting the effectiveness of this learning-based inspection strategy.
    <b>Keywords:</b> PV inspection, UAV path tracking, Goal-Conditioned Reinforcement Learning, PPO, Zigzag trajectory, Wind robustness, Autonomous drone coverage.}
}