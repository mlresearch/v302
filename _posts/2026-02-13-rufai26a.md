---
title: Towards End-to-End Training of Automatic Speech Recognition for Nigerian Pidgin
abstract: 'The prevalence of automatic speech recognition (ASR) systems in spoken
  language applications has increased significantly in recent years. Notably, many
  African languages lack sufficient linguistic resources to support the robustness
  of these systems. This paper focuses on the development of an end-to-end speech
  recognition system customised for Nigerian Pidgin English. We investigated and evaluated
  different pretrained state-of-the-art architectures on a new dataset. Our empirical
  results demonstrate a notable performance of the variant Wav2Vec2 XLSR-53 on our
  dataset, achieving a word error rate (WER) of 29.6% on the test set, surpassing
  other architectures such as NeMo QuartzNet and Wav2Vec2.0 Base-100H in quantitative
  assessments. Additionally, we demonstrate that a pretrained state-of-the-art model
  does not work well out-of-the-box. We performed zero-shot evaluation using XLSR-English
  as the baseline, chosen for its similarity to Nigerian Pidgin. This yielded a higher
  WER of 73.7%. By adapting this architecture to nuances represented in our dataset,
  we reduce error by 59.84%. Our dataset comprises 4,277 recorded utterances from
  native speakers, partitioned into training, validation, and test sets. This study
  underscores the potential for improving ASR systems for under-resourced languages
  like Nigerian Pidgin English, contributing to greater inclusion in speech technology
  applications. We publicly release our unique parallel dataset (speech-to-text) on
  Nigerian Pidgin, as well as the model weights on Hugging Face. Our project and code
  are made available to foster future research from the community. <b>Keywords</b>:
  Automatic Speech Recognition, ASR, Nigerian Pidgin English, End-to-End.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: rufai26a
month: 0
tex_title: Towards End-to-End Training of Automatic Speech Recognition for Nigerian
  Pidgin
firstpage: 1
lastpage: 10
page: 1-10
order: 1
cycles: false
bibtex_author: Rufai, Amina and Abeeb, Afolabi and Oduntan, Esther and Arulogun, Tayo
  and Adegboro, Oluwabukola and Ajisafe, Daniel
author:
- given: Amina
  family: Rufai
- given: Afolabi
  family: Abeeb
- given: Esther
  family: Oduntan
- given: Tayo
  family: Arulogun
- given: Oluwabukola
  family: Adegboro
- given: Daniel
  family: Ajisafe
date: 2026-02-13
address:
container-title: DLI 2025 Research Track
volume: '302'
genre: inproceedings
issued:
  date-parts:
  - 2026
  - 2
  - 13
pdf: https://raw.githubusercontent.com/mlresearch/v302/main/assets/rufai26a/rufai26a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
